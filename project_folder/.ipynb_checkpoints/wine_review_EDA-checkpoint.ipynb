{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "The data was collected from Kaggle @ https://www.kaggle.com/zynicide/wine-reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing data and cleaning descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "\n",
    "data = pd.read_csv(\"winemag-data_first150k.csv\", index_col = False)\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Note: add plotly charts for Towards Data Science Article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Unnamed: 0','region_2','designation'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# set seaborn style \n",
    "plt.figure(figsize=(20,15))\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "newStopWords = ['wine','flavors']\n",
    "stopwords = stopwords.words('english')\n",
    "stopwords.extend(newStopWords)\n",
    "stopwords = set(stopwords)\n",
    "\n",
    "detokenizer = TreebankWordDetokenizer()\n",
    "\n",
    "def clean_description(desc):\n",
    "    desc = word_tokenize(desc.lower())\n",
    "    desc = [token for token in desc if token not in stopwords and token.isalpha()]\n",
    "    return detokenizer.detokenize(desc)\n",
    "\n",
    "data[\"cleaned_description\"] = data[\"description\"].apply(clean_description)\n",
    "\n",
    "word_occurrence = data[\"cleaned_description\"].str.split(expand=True).stack().value_counts()\n",
    "\n",
    "total_words = sum(word_occurrence)\n",
    "\n",
    "# plot most common words \n",
    "\n",
    "top_words = word_occurrence[:30]/total_words\n",
    "\n",
    "ax = sns.barplot(x = top_words.values, y = top_words.index)\n",
    "\n",
    "# Setting title \n",
    "ax.set_title(\"% Occurrence of Most Frequent Words\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Finding the weights of country wine production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_by_country = data[[\"price\", \"country\"]].dropna(how = \"any\")\n",
    "\n",
    "# Remove all data greater than the 98th percentile\n",
    "val = prices_by_country[\"price\"].quantile(0.98)\n",
    "prices_by_country = prices_by_country[prices_by_country[\"price\"] < val]\n",
    "\n",
    "# Only consider countries where at least 100 wines have been reviewed\n",
    "prices_by_country = prices_by_country.groupby(\"country\").filter(lambda x: (x[\"price\"].count() >= 100))\n",
    "\n",
    "# Creating a boxplot\n",
    "plt.figure(figsize=(20,15))\n",
    "ax = sns.boxplot(x=\"country\", y = \"price\", data=prices_by_country)\n",
    "\n",
    "# Setting title \n",
    "ax.set_title(\"Wine Prices by Country\")\n",
    "\n",
    "# Assuming prices are in USD since its an American website\n",
    "ax.set(xlabel = \"Origin Country\", ylabel = \"Price in USD\")\n",
    "\n",
    "# Making sure ticks aren't overlapping\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45,ha=\"right\",rotation_mode='anchor')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price by Country\n",
    "\n",
    "Looking at the chart above there are a couple interesting findings. For example, why does Hungary have such a large range compared to all the other countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_by_variety = data[[\"price\", \"variety\"]].dropna(how = \"any\")\n",
    "\n",
    "# Remove all data greater than the 98th percentile\n",
    "val = prices_by_variety[\"price\"].quantile(0.98)\n",
    "prices_by_variety = prices_by_variety[prices_by_variety[\"price\"] < val]\n",
    "\n",
    "# Only consider varieties where at least 500 wines have been reviewed\n",
    "prices_by_variety = prices_by_variety.groupby(\"variety\").filter(lambda x: (x[\"price\"].count() >= 500))\n",
    "\n",
    "# Creating a boxplot\n",
    "plt.figure(figsize=(20,15))\n",
    "ax = sns.boxplot(x=\"variety\", y = \"price\", data=prices_by_variety)\n",
    "\n",
    "# Setting title \n",
    "ax.set_title(\"Wine Prices by Variety\")\n",
    "\n",
    "# Assuming prices are in USD since its an American website\n",
    "ax.set(xlabel = \"Origin Country\", ylabel = \"Price in USD\")\n",
    "\n",
    "# Making sure ticks aren't overlapping\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45,ha=\"right\",rotation_mode='anchor')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_by_price = data[[\"price\", \"points\"]]\n",
    "\n",
    "# Remove all data greater than the 98th percentile\n",
    "val = prices_by_variety[\"price\"].quantile(0.98)\n",
    "ratings_by_price = ratings_by_price[ratings_by_price[\"price\"] < val]\n",
    "\n",
    "\n",
    "ax = sns.lmplot(x = \"price\", y = \"points\", data = ratings_by_price, height = 10, aspect = 1)\n",
    "\n",
    "# Assuming prices are in USD since its an American website\n",
    "ax.set(xlabel = \"Price in USD\", ylabel = \"Wine Rating\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a rating system\n",
    "Reading through the book Wine Folly as well as looking on the Wine Enthusiast website, I came across an excellent point system that I will use to categorize the groups. You can read more about it here: https://winefolly.com/tips/wine-ratings-explained/\n",
    "\n",
    "TLDR:\n",
    "\n",
    "The wine rating system was developed back in the 80s which scored wines based on production quality and typicity, (how much the traits of the particular wine typify the style and region its from). Another way to think of it is like a dog show, the winner is the dog which explifies its breed. Any unique features that are not typical will score it lower on the point system. \n",
    "\n",
    "Ratings\n",
    "95 - 100    The benchmark examples or 'Classic'\n",
    "90 - 94     Superior to Exceptional\n",
    "85 - 90     Good to veru good\n",
    "80 - 84     Above average to good\n",
    "70 - 79     Flawed wines and taste average\n",
    "60 - 69     Wines are flawed and not recommended but drinkable\n",
    "50 - 59     Wines are flawed and undrinkable\n",
    "\n",
    "Interestingly, the dataset has no wines with a score under 80 which alludes again that only the better wines are scored. Additionally there are a couple notable flaws in this system: wine rating intervals vary depending on the different rating sites. For example:\n",
    "\n",
    "Wine & Spirits magazine says 86 - 89 is highly recommended, whereas Wine Enthusiast Magazine says 85 - 89 is very good. Because of this, I am using Wine Folly's system because the site is used as a training resource for sommeliers, thus offering a solid 3rd party system.\n",
    "\n",
    "I will be adopting this same point interval system for my classes 0 - 4.\n",
    "\n",
    "##### Note for the rating system:\n",
    "Due to issues surrounding biases that arise in self rating systems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Points to Classes \n",
    "\n",
    "# Note: I found that I had to adjust the class ranges below in order to capture the 100point wines and ensure none were left out.\n",
    "def points_to_class(points):\n",
    "    if points in range(79,85):\n",
    "        return 0\n",
    "    elif points in range(84,90):\n",
    "        return 1\n",
    "    elif points in range(89,95):\n",
    "        return 2\n",
    "    elif points in range(94,101):\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "    \n",
    "data['rating'] = data['points'].apply(points_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As expected the data is imbalanced.\n",
    "# Interestingly, this falls inline with the expected results\n",
    "# Wine Folly's rating bell curve shows that a majority of the ratings fall between 87 - 89 points\n",
    "# as seen below and in the link provided earlier\n",
    "\n",
    "sns.histplot(data = data, x = 'points', stat = 'density', binwidth=1, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now creating a new column with our newly designated rating classes as \"rating\".\n",
    "data[\"rating\"] = data[\"points\"].apply(points_to_class)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diving deeper with Sentiment, Word Count, and Sentence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "#Creating a sentiment column\n",
    "data['sentiment'] = data['cleaned_description'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "# Creating words and Sentence length columns\n",
    "data['word_count'] = data['cleaned_description'].apply(lambda x: len(str(x).split()))\n",
    "data['review_len'] = data['cleaned_description'].astype(str).apply(len)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given our data is mainly the higher end wines and those that are score, I'd assume there would be a skwew in the sentiment\n",
    "# Clearly below, we can see there is a much higher concentration of positive vs negative sentiment.\n",
    "plt.figure(figsize=(50,30))\n",
    "plt.margins(0.02)\n",
    "plt.xlabel('Sentiment', fontsize=50)\n",
    "plt.xticks(fontsize=40)\n",
    "plt.ylabel('Frequency', fontsize=50)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.hist(data['sentiment'], bins=50)\n",
    "plt.title('Sentiment Distribution', fontsize=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additionally, looking at how sentiment is distributed over the points and the rating system I created\n",
    "# It is clear that the average positive sentiment per-point/rating class is higher for the highly rated wines.\n",
    "\n",
    "polarity_avg = data.groupby('points')['sentiment'].mean().plot(kind='bar', figsize=(50,30))\n",
    "plt.xlabel('Points', fontsize=45)\n",
    "plt.ylabel('Average Sentiment', fontsize=45)\n",
    "plt.xticks(fontsize=40)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.title('Average Sentiment per Points Distribution', fontsize=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_rating = data.groupby('rating')['sentiment'].mean().plot(kind='bar', figsize=(50,30))\n",
    "plt.xlabel('Points', fontsize=45)\n",
    "plt.ylabel('Average Sentiment', fontsize=45)\n",
    "plt.xticks(fontsize=40)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.title('Average Sentiment per Points Distribution', fontsize=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets look at how sentiment is towards the most rated countries.\n",
    "sentiment_by_country = data[[\"sentiment\", \"country\"]].dropna(how = \"any\")\n",
    "\n",
    "# Only consider countries where at least 100 wines have been reviewed\n",
    "sentiment_by_country = sentiment_by_country.groupby(\"country\").filter(lambda x: (x[\"sentiment\"].count() >= 100))\n",
    "\n",
    "# Creating a boxplot\n",
    "plt.figure(figsize=(20,15))\n",
    "ax = sns.boxplot(x=\"country\", y = \"sentiment\", data=sentiment_by_country)\n",
    "\n",
    "# Setting title \n",
    "ax.set_title(\"Wine Sentiment by Country\")\n",
    "\n",
    "# Assuming prices are in USD since its an American website\n",
    "ax.set(xlabel = \"Origin Country\", ylabel = \"Sentiment\")\n",
    "\n",
    "# Making sure ticks aren't overlapping\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45,ha=\"right\",rotation_mode='anchor')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_polarity = sentiment_by_country.groupby('country')['sentiment'].mean().plot(kind='bar', figsize=(50,30))\n",
    "plt.xlabel('country', fontsize=45)\n",
    "plt.ylabel('Average Sentiment', fontsize=45)\n",
    "plt.xticks(fontsize=40)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.title('Average Sentiment per Points Distribution', fontsize=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at average rating class between countries.\n",
    "rating_by_country = data[[\"rating\", \"country\"]].dropna(how = \"any\")\n",
    "\n",
    "# Only consider countries where at least 100 wines have been reviewed\n",
    "rating_by_country = rating_by_country.groupby(\"country\").filter(lambda x: (x[\"rating\"].count() >= 100))\n",
    "\n",
    "polarity_rating = rating_by_country.groupby('country')['rating'].mean().plot(kind='bar', figsize=(50,30))\n",
    "plt.xlabel('Country', fontsize=45)\n",
    "plt.ylabel('Average rating', fontsize=45)\n",
    "plt.xticks(fontsize=40)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.title('Average Rating per Country Distribution', fontsize=50)\n",
    "plt.axhline(rating_by_country['rating'].mean(), color='r',fillstyle = 'full', linestyle='dashed', linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Looking at average rating class between Provinces.\n",
    "rating_by_province = data[[\"rating\", \"province\"]].dropna(how = \"any\")\n",
    "\n",
    "# Only consider Provinces where at least 500 wines have been reviewed\n",
    "rating_by_province = rating_by_province.groupby(\"province\").filter(lambda x: (x[\"rating\"].count() >= 500))\n",
    "\n",
    "polarity_rating = rating_by_province.groupby('province')['rating'].mean().plot(kind='bar', figsize=(50,30))\n",
    "plt.xlabel('Province', fontsize=45)\n",
    "plt.ylabel('Average rating', fontsize=45)\n",
    "plt.xticks(fontsize=40)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.title('Average Rating per Province Distribution', fontsize=50)\n",
    "plt.axhline(rating_by_province['rating'].mean(), color='r',fillstyle = 'full', linestyle='dashed', linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at average rating class between Varieties.\n",
    "rating_by_variety = data[[\"rating\", \"variety\"]].dropna(how = \"any\")\n",
    "\n",
    "# Only consider Provinces where at least 500 wines have been reviewed\n",
    "rating_by_variety = rating_by_variety.groupby(\"variety\").filter(lambda x: (x[\"rating\"].count() >= 500))\n",
    "\n",
    "polarity_rating = rating_by_variety.groupby('variety')['rating'].mean().plot(kind='bar', figsize=(50,30))\n",
    "plt.xlabel('Variety', fontsize=45)\n",
    "plt.ylabel('Average rating', fontsize=45)\n",
    "plt.xticks(fontsize=40)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.title('Average Rating per Variety Distribution', fontsize=50)\n",
    "plt.axhline(rating_by_variety['rating'].mean(), color='r',fillstyle = 'full', linestyle='dashed', linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing High scoring Countries vs Low Scoring countries using weighted average\n",
    "\n",
    "From the chart above we can see that there is an average rating cut off is just below 1.2. But this does not take into account the respresentive quantity of ratings in each country. It is important to take this into account because a country who produces alot of wine can be brough closer to the average.\n",
    "\n",
    "To break this down further, I will need to find the quantities of the varieties by each country, and then calculated the weighted average points and ratings by country. I could break this down futher and even find the weighted average by variety as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_features = data[['country','province','points','rating','variety']]\n",
    "wf = weighted_features.groupby(['country'].filter(lambda x: (x['points'].count() >= 100)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_by_x = data[['points','country', 'variety', 'province']].dropna(how = \"any\")\n",
    "\n",
    "# Only consider countries where at least 100 wines have been reviewed\n",
    "points_by_x = points_by_x.groupby(['country', 'variety', 'province']).filter(lambda x: (x[\"points\"].count() >= 100))\n",
    "\n",
    "a_df = points_by_x.loc[points_by_x['country'] == 'Argentina']\n",
    "\n",
    "#weight of points per country\n",
    "argentina_point_weights = a_df.points.value_counts() / a_df.points.count()\n",
    "\n",
    "#weight of varieties per country\n",
    "argentina_variety_weights = a_df.variety.value_counts() / a_df.variety.count()\n",
    "\n",
    "vwdf = pd.DataFrame(argentina_variety_weights, columns = ['wt', 'variety'])\n",
    "#weight of ratings per country\n",
    "\n",
    "#weight of sentiment per country\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argentina_variety_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = data[['points','country', 'variety', 'province']].dropna(how = \"any\")\n",
    "\n",
    "df_f = df_f.groupby(['country', 'variety', 'province']).filter(lambda x: (x[\"points\"].count() >= 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = data[['points','country', 'variety', 'province']].dropna(how = \"any\")\n",
    "df_f = df_f.groupby(['country', 'variety', 'province']).filter(lambda x: (x[\"points\"].count() >= 100))\n",
    "df_f.variety.value_counts()/df_f.variety.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f.province.value_counts()/df_f.province.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f.country.value_counts()/df_f.country.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Normalize columns to better understand country/province relationships with varieties, ratings, provinces and sentiment\n",
    "def find_weights(df):\n",
    "     \n",
    "    for features in df[]:\n",
    "        features = df[['country','province','points','rating','variety']].dropna(how = \"any\")\n",
    "        \n",
    "    for name in df['country']:\n",
    "        \n",
    "        sum_var_occur = df.loc[df['country'] == name].value_counts()\n",
    "        print(sum_var_occur)\n",
    "        \n",
    "find_weights(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  country_name_df = \n",
    "    country_name_df_weights = country_name_df.variety.value_counts() / country_name_df.variety.count()\n",
    "    print(country_name_df_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vwdf.reset_index(inplace=True)\n",
    "vwdf =vwdf.rename(columns = {'index' : 'variety', 'variety':'wt', 'wt':'na'})\n",
    "\n",
    "vwdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vwdf= vwdf.drop(['na'], axis=1)\n",
    "vwdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argentina_weights_to_variety(variety):\n",
    "    if variety in vwdf['variety']:   \n",
    "        return vwdf['wt']\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "a_df['v_wt'] = a_df['variety'].apply(argentina_weights_to_variety)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets look at the weight of the frequencies between the high rating countries and the low rating countries\n",
    "def wavg(group, avg_name, weight_name):\n",
    "    d = group[avg_name]\n",
    "    w = group[weight_name]\n",
    "    try:\n",
    "        return (d * w).sum()/w.sum()\n",
    "    except ZeroDivisionError:\n",
    "        return d.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_df.points.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Granular: Wine Points by Variety\n",
    "\n",
    "As previously mentioned when creating a rating class system, points are scored based on how the wine typifies its variety. Thus it is prudent to also look at how the point and sentiment distribution looks by variety as well to gain a better understanding of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_by_variety = data[[\"points\", \"variety\"]].dropna(how = \"any\")\n",
    "\n",
    "# Only consider varieties where at least 500 wines have been reviewed\n",
    "points_by_variety = points_by_variety.groupby(\"variety\").filter(lambda x: (x[\"points\"].count() >= 500))\n",
    "\n",
    "# Creating a boxplot\n",
    "plt.figure(figsize=(20,15))\n",
    "ax = sns.boxplot(x='variety', y = 'points', data=points_by_variety)\n",
    "\n",
    "# Setting title \n",
    "ax.set_title(\"Wine Points by Variety\")\n",
    "\n",
    "ax.set(xlabel = \"Wine Variety\", ylabel = \"Wine Points\")\n",
    "\n",
    "# Making sure ticks aren't overlapping\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45,ha=\"right\",rotation_mode='anchor')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix this in plotly\n",
    "\n",
    "variety_sentiment = data.groupby('variety')['sentiment'].mean().plot(kind='bar', figsize=(70,30))\n",
    "plt.xlabel('Variety', fontsize=45)\n",
    "plt.ylabel('Average Sentiment', fontsize=45)\n",
    "plt.xticks(fontsize=40)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.title('Average Sentiment per Variety Distribution', fontsize=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['country'] =df['country'].astype('category')\n",
    "df['province'] =df['province'].astype('category')\n",
    "df['variety'] =df['variety'].astype('category')\n",
    "df['winery'] =df['winery'].astype('category')\n",
    "\n",
    "\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "df['country_cat'] = le.fit_transform(df['country'])\n",
    "\n",
    "dummy_varieties = pd.get_dummies(df['variety'])\n",
    "\n",
    "df = pd.concat([df, dummy_varieties], axis=1)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Looking at the specific stats between countries.\n",
    "#This will also be used to eliminate outlier countries who's sum point counts are below the average.\n",
    "\n",
    "#defining stats function with .describe() and .skew()\n",
    "def stats(x):\n",
    "    results = pd.concat([x.describe(), x.skew()], axis=1)\n",
    "    print(results)\n",
    "\n",
    "stats(df[['country', 'points']].groupby('country'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def corr_heatmap(df):\n",
    "    corr = df.corr()\n",
    "    fig = plt.figure(figsize=(25,20))\n",
    "    ax = sns.heatmap(corr, vmin=-1, vmax=1, cmap=\"coolwarm\", linewidths=0.5, annot=True)\n",
    "    ax.set_title(\"Correlation matrix\")\n",
    "    \n",
    "    return ax\n",
    "\n",
    "corr_heatmap(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nums = df.drop(['province', 'variety', 'winery',\n",
    "       'description', 'rating_description_str', 'tokenized', 'lemmatized',\n",
    "       'lemma_str'], axis=1)\n",
    "import ppscore as pps\n",
    " \n",
    "\n",
    "def heatmap(df):\n",
    "    fig = plt.figure(figsize=(70,50))\n",
    "    df = df[['x', 'y', 'ppscore']].pivot(columns='x', index='y', values='ppscore')\n",
    "    ax = sns.heatmap(df, vmin=0, vmax=1, cmap=\"coolwarm\", linewidths=0.5, annot=True)\n",
    "    ax.set_title(\"PPS matrix\")\n",
    "    ax.set_xlabel(\"feature\")\n",
    "    ax.set_ylabel(\"target\")\n",
    "    return ax\n",
    "\n",
    "matrix = pps.matrix(df_nums)\n",
    "\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review of the Correlation and PPS tables\n",
    "The Correlation and PPS tables above reveal some interesting findings about the data:\n",
    "\n",
    "1) the relation between countries and points\n",
    "2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF-NMF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df =25, max_features=5000, use_idf=True)\n",
    "tfidf = tfidf_vectorizer.fit_transform(df['lemma_str'])\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "doc_term_matrix_tfidf = pd.DataFrame(tfidf.toarray(), columns=list(tfidf_feature_names))\n",
    "doc_term_matrix_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "nmf = NMF(n_components=15, random_state=0, alpha=.1, init='nndsvd').fit(tfidf)\n",
    "display_topics(nmf, tfidf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.9, min_df=25, max_features=5000)\n",
    "tf = tf_vectorizer.fit_transform(new_df['lemma_str'].values.astype('U'))\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "doc_term_matrix = pd.DataFrame(tf.toarray(), columns=list(tf_feature_names))\n",
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components=10, learning_method='online', max_iter=500, random_state=0).fit(tf)\n",
    "no_top_words = 10\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                          for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "             \n",
    "display_topics(lda_model, tf_feature_names, no_top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda_model, tf, tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing topics generated between LDA and NMF models:\n",
    "\n",
    "Looking over the two sets if topics, it appears the NMF model generates much better overall topic descriptions than the LDA model based a sommelier book called Wine Folly which offer descriptions on wines and how to translate the different descriptions. (will be creating a vectorization model from this later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nmf_topic_values = nmf.transform(tfidf)\n",
    "df['nmf_topics'] = nmf_topic_values.argmax(axis=1)\n",
    "lda_topic_values = lda_model.transform(tf)\n",
    "df['lda_topics'] = lda_topic_values.argmax(axis=1)\n",
    "lda_remap = {0: 'flavor apple citrus acidity wine crisp peach white finish fruit',\n",
    "             1: 'fruit seem noir pinot new go acid perfume bit acidic',\n",
    "             2: 'cherry black tannin cabernet blend blackberry finish dry merlot drink',\n",
    "             3: 'wine import vineyard year vintage one grape time intense pie',\n",
    "             4: 'cherry flavor raspberry dry little cola spice simple pinot red',\n",
    "             5: 'flavor finish palate fruit berry plum aroma big feel herbal',\n",
    "             6: 'wine fruit spice aroma aromas berry mouth note bright offer',\n",
    "             7: 'flavor wine oak sweet rich good blackberry best like show',\n",
    "             8: 'finish flavor style palate nose sweet light candy hint note',\n",
    "             9: 'wine fruit acidity ripe age tannin year flavor rich structure'}\n",
    "df['lda_topics'] = df['lda_topics'].map(lda_remap)\n",
    "nmf_remap = {0: 'finish berry palate nose plum aroma herbal note flavor feel',\n",
    "             1: 'oak vanilla toast pineapple chardonnay butter rich flavor creamy acidity',\n",
    "             2: 'wine fruit age year ripe structure wood rich well tannin',\n",
    "             3: 'pinot cherry noir raspberry cola silky flavor red drink spice', \n",
    "             4: 'acidity fresh light fruity wine bright red drink crisp attractive',\n",
    "             5: 'sweet soft simple taste like flavor candy wine little jammy',\n",
    "             6: 'cabernet blend sauvignon merlot franc syrah verdot petit blanc sangiovese',\n",
    "             7: 'apple citrus white peach green crisp pear lemon clean lime',\n",
    "             8: 'black cherry spice tannin dark pepper chocolate offer blackberry licorice',\n",
    "             9: 'dry blackberry good currant flavor tannic show drink tannin wine'}\n",
    "df['nmf_topics'] = df['nmf_topics'].map(nmf_remap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_x = df['nmf_topics'].value_counts()\n",
    "nmf_y = nmf_x.sort_index()\n",
    "plt.figure(figsize=(50,30))\n",
    "sns.barplot(nmf_x, nmf_y.index)\n",
    "plt.title(\"NMF Topic Distribution\", fontsize=50)\n",
    "plt.ylabel('Review Topics', fontsize=50)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.xlabel('Frequency', fontsize=50)\n",
    "plt.xticks(fontsize=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_low_points = df.loc[(df['points']==80) | (df['points']==87)]\n",
    "nmf_low_x = df_low_points['nmf_topics'].value_counts()\n",
    "nmf_low_y = nmf_low_x.sort_index()\n",
    "plt.figure(figsize=(50,30))\n",
    "sns.barplot(nmf_low_x, nmf_low_y.index)\n",
    "plt.title(\"NMF Topic Distribution for Low Points (1 & 2)\", fontsize=50)\n",
    "plt.ylabel('Frequency', fontsize=50)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.xlabel('Review Topics', fontsize=50)\n",
    "plt.xticks(fontsize=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_ratings = df.loc[(df['points']==88) | (df['points']==100)]\n",
    "nmf_high_x = df_high_ratings['nmf_topics'].value_counts()\n",
    "nmf_high_y = nmf_high_x.sort_index()\n",
    "plt.figure(figsize=(50,30))\n",
    "sns.barplot(nmf_high_x, nmf_high_y.index)\n",
    "plt.title(\"NMF Topic Distribution for High Points (3 & 4)\", fontsize=50)\n",
    "plt.ylabel('Frequency', fontsize=50)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.xlabel('Review Topics', fontsize=50)\n",
    "plt.xticks(fontsize=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines_new= wines.drop(['lemmatized', 'points'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([df, wines_new], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rating = new_df.points.value_counts()\n",
    "y_rating = x_rating.sort_index()\n",
    "plt.figure(figsize=(50,30))\n",
    "sns.barplot(x_rating.index, x_rating.values, alpha=0.8)\n",
    "plt.title(\"Point Distribution\", fontsize=50)\n",
    "plt.ylabel('Frequency', fontsize=50)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.xlabel('Wine Points', fontsize=50)\n",
    "plt.xticks(fontsize=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_avg = new_df.groupby('points')['review_len'].mean().plot(kind='bar', figsize=(50,30))\n",
    "plt.xlabel('Points', fontsize=35)\n",
    "plt.ylabel('Count of Letters in Points', fontsize=35)\n",
    "plt.xticks(fontsize=40)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.title('Average Number of Letters per Points Distribution', fontsize=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_avg = new_df.groupby('points')['word_count'].mean().plot(kind='bar', figsize=(50,30))\n",
    "plt.xlabel('Points', fontsize=35)\n",
    "plt.ylabel('Count of Words in Points', fontsize=35)\n",
    "plt.xticks(fontsize=40)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.title('Average Number of Words per Points Distribution', fontsize=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = new_df[['points','sentiment', 'review_len', 'word_count']].corr()\n",
    "mask = np.zeros_like(correlation, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "plt.figure(figsize=(50,30))\n",
    "plt.xticks(fontsize=40)\n",
    "plt.yticks(fontsize=40)\n",
    "sns.heatmap(correlation, cmap='coolwarm', annot=True, annot_kws={\"size\": 40}, linewidths=10, vmin=-1.5, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = new_df['lemmatized']\n",
    "\n",
    "words_nmf = new_df['nmf_topics']\n",
    "\n",
    "words_lda = new_df['lda_topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostcommon = FreqDist(word).most_common(100)\n",
    "wordcloud = WordCloud(width=1600, height=800, background_color='white').generate(str(mostcommon))\n",
    "fig = plt.figure(figsize=(30,10), facecolor='white')\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.title('Top 100 Most Common Words', fontsize=100)\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostcommon = FreqDist(words_nmf).most_common(100)\n",
    "wordcloud = WordCloud(width=1600, height=800, background_color='white').generate(str(mostcommon))\n",
    "fig = plt.figure(figsize=(30,10), facecolor='white')\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.title('Top 100 Most Common Words', fontsize=100)\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostcommon = FreqDist(words_lda).most_common(100)\n",
    "wordcloud = WordCloud(width=1600, height=800, background_color='white').generate(str(mostcommon))\n",
    "fig = plt.figure(figsize=(30,10), facecolor='white')\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.title('Top 100 Most Common Words', fontsize=100)\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.drop(['province', 'variety'], axis=1)\n",
    "new_df.to_csv('winesft_w_models.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.loc[new_df['points'] == 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(200,50))\n",
    "plt.xticks(fontsize=40)\n",
    "ax = sns.boxplot(x=\"country\", y=\"points\", data=new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect_sen = new_df.loc[new_df['sentiment'] == 1]\n",
    "plt.figure(figsize=(100,50))\n",
    "plt.xticks(fontsize=40)\n",
    "ax = sns.boxplot(x=\"country\", y=\"points\", data=perfect_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
